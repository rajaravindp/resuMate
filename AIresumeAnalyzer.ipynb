{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install all dependencies using:\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "rAL5IgXWWe9k"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Provide OpenAI API key\n",
        "openai_api_key = input('Enter you OpenAI API Key: ')"
      ],
      "metadata": {
        "id": "7Xjo_G0xW6mf"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "rUcQO6y1_GXV"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "F5UqejmqWLPO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to resume\n",
        "myResume = \"/content/aravind-resume-palepu.pdf\"\n",
        "pdf_resume = PdfReader(myResume)"
      ],
      "metadata": {
        "id": "9GOhGjEXXxHH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extrat text from each page separately\n",
        "txt = \"\"\n",
        "for page in pdf_resume.pages:\n",
        "    txt += page.extract_text()\n",
        "\n",
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOJ-r8i9X2_z",
        "outputId": "50e6ead8-9bd9-4195-a0e5-ba19cdaf9cfe"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARAVIND RAJ PALEPU   \n",
            "Richardson, TX – 75082, (314)-386-7056 | aravindrajpalepu@gmail.com  | LinkedIn | GitHub | Tableau Public   \n",
            " \n",
            "EDUCATION   \n",
            "University of Texas at Dallas                    May 2024  \n",
            "Master of Science, Business Analytics - Data Science Track         \n",
            "Symbiosis International University                               May 2021  \n",
            "Bachelor of Business Administration and Bachelor of Laws \n",
            "                               \n",
            "TECHNICAL SKILLS   \n",
            "Technical: SkLearn, XGBoost, PyTorch, FastAI, OpenCV2, NLTK, HuggingFace Transformers, Langchain, Streamlit \n",
            "Analytical Tools: SQL, Python, R, Tableau, Power B.I , Google Analytics, VBA/Macros, MS Excel \n",
            "Data Management:  PySpark, Postgres, PL/pgSQL, MongoDB, Databricks, Apache Airflow, AWS Redshift \n",
            "Certifications:  AWS Solutions Architect, OCI Foundations, OCI AI Foundations, Alteryx Micro-Credentials \n",
            " \n",
            "PROFESSIONAL EXPERIENCE   \n",
            "Smart Data Solutions, Eagan, Minnesota                January 2024 – May 2024 \n",
            "Machine Learning Intern \n",
            " Fined-tuned OCR solutions to efficiently extract health related textual data from scanned documents, thereby \n",
            "enhancing data accuracy.  \n",
            " Leveraged transformer-based models to deliver advanced NER systems to accurately identify and classify targeted \n",
            "healthcare associated entities, including PII, diseases, medications, and medical procedures within a wide range of \n",
            "unstructured medical data.  \n",
            "SplashBI, Hyderabad, India                              January 2022 – July 2022 \n",
            "Data Intern  \n",
            " Developed an employee attrition prediction model  with 93% recall  and 91% accuracy  using various machine \n",
            "learning models in Python, providing valuable insights into factors influencing employee turnover.  \n",
            " Deployed a dynamic Tableau dashboard, facilitating a nuanced exploration of attrition trends, thereby enabling \n",
            "proactive attrition risk mitigation , and contributing to a 25% enhancement in the efficacy of retention strategies. \n",
            " Executed data extraction and manipulation using SQL queries in AWS Redshift  to develop analysis reports and \n",
            "presentations for the senior management.  \n",
            " \n",
            "ACADEMIC PROJECTS   \n",
            "Natural Language processing Interface to Postgres       August 2023 – December 2023  \n",
            " Scraped data from Tesla's preowned inventory website using Selenium , capturing key variables related to car \n",
            "listings and established comprehensive data quality checks to validate data types and identify anomalies in data.  \n",
            " Developed a large language model application using Langchain , Google PaLM 2 , Hugging Face Transformers  \n",
            "and Streamlit  to dynamically query the data in Postgres in natural language.  \n",
            " Generated word embeddings using Chroma's sentence transformers for enhanced semantic search, elevating the \n",
            "precision and effectiveness of information retrieval.  \n",
            "Plant Pathology Detection         August 2023 – December 2023 \n",
            " Built a robust multi-label classification system using ResNet and GoogLeNet  to accurately classify Foliar disease  \n",
            "in apple trees. \n",
            " Introduced Grad-CAM  interpretability to highlight key image regions influencing classification, bolstering \n",
            "transparency and confidence in model predictions. \n",
            " Implemented a scalable and user-friendly web interface for real-time disease detection , allowing users to upload \n",
            "and analyze images, instantly receive classification results, and visualize model explanations for decision \n",
            "transparency. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the resume text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700,\n",
        "                                               chunk_overlap=200,\n",
        "                                               length_function=len)\n",
        "\n",
        "resume_chunks = text_splitter.split_text(text=txt)\n",
        "print(resume_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g3E1pQ5X8tl",
        "outputId": "2f6500f6-a494-4bc4-e29b-53a5b2c13012"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ARAVIND RAJ PALEPU   \\nRichardson, TX – 75082, (314)-386-7056 | aravindrajpalepu@gmail.com  | LinkedIn | GitHub | Tableau Public   \\n \\nEDUCATION   \\nUniversity of Texas at Dallas                    May 2024  \\nMaster of Science, Business Analytics - Data Science Track         \\nSymbiosis International University                               May 2021  \\nBachelor of Business Administration and Bachelor of Laws \\n                               \\nTECHNICAL SKILLS   \\nTechnical: SkLearn, XGBoost, PyTorch, FastAI, OpenCV2, NLTK, HuggingFace Transformers, Langchain, Streamlit \\nAnalytical Tools: SQL, Python, R, Tableau, Power B.I , Google Analytics, VBA/Macros, MS Excel', 'Analytical Tools: SQL, Python, R, Tableau, Power B.I , Google Analytics, VBA/Macros, MS Excel \\nData Management:  PySpark, Postgres, PL/pgSQL, MongoDB, Databricks, Apache Airflow, AWS Redshift \\nCertifications:  AWS Solutions Architect, OCI Foundations, OCI AI Foundations, Alteryx Micro-Credentials \\n \\nPROFESSIONAL EXPERIENCE   \\nSmart Data Solutions, Eagan, Minnesota                January 2024 – May 2024 \\nMachine Learning Intern \\n\\uf0b7 Fined-tuned OCR solutions to efficiently extract health related textual data from scanned documents, thereby \\nenhancing data accuracy.  \\n\\uf0b7 Leveraged transformer-based models to deliver advanced NER systems to accurately identify and classify targeted', 'enhancing data accuracy.  \\n\\uf0b7 Leveraged transformer-based models to deliver advanced NER systems to accurately identify and classify targeted \\nhealthcare associated entities, including PII, diseases, medications, and medical procedures within a wide range of \\nunstructured medical data.  \\nSplashBI, Hyderabad, India                              January 2022 – July 2022 \\nData Intern  \\n\\uf0b7 Developed an employee attrition prediction model  with 93% recall  and 91% accuracy  using various machine \\nlearning models in Python, providing valuable insights into factors influencing employee turnover.', 'learning models in Python, providing valuable insights into factors influencing employee turnover.  \\n\\uf0b7 Deployed a dynamic Tableau dashboard, facilitating a nuanced exploration of attrition trends, thereby enabling \\nproactive attrition risk mitigation , and contributing to a 25% enhancement in the efficacy of retention strategies. \\n\\uf0b7 Executed data extraction and manipulation using SQL queries in AWS Redshift  to develop analysis reports and \\npresentations for the senior management.  \\n \\nACADEMIC PROJECTS   \\nNatural Language processing Interface to Postgres       August 2023 – December 2023', \"presentations for the senior management.  \\n \\nACADEMIC PROJECTS   \\nNatural Language processing Interface to Postgres       August 2023 – December 2023  \\n\\uf0b7 Scraped data from Tesla's preowned inventory website using Selenium , capturing key variables related to car \\nlistings and established comprehensive data quality checks to validate data types and identify anomalies in data.  \\n\\uf0b7 Developed a large language model application using Langchain , Google PaLM 2 , Hugging Face Transformers  \\nand Streamlit  to dynamically query the data in Postgres in natural language.  \\n\\uf0b7 Generated word embeddings using Chroma's sentence transformers for enhanced semantic search, elevating the\", \"and Streamlit  to dynamically query the data in Postgres in natural language.  \\n\\uf0b7 Generated word embeddings using Chroma's sentence transformers for enhanced semantic search, elevating the \\nprecision and effectiveness of information retrieval.  \\nPlant Pathology Detection         August 2023 – December 2023 \\n\\uf0b7 Built a robust multi-label classification system using ResNet and GoogLeNet  to accurately classify Foliar disease  \\nin apple trees. \\n\\uf0b7 Introduced Grad-CAM  interpretability to highlight key image regions influencing classification, bolstering \\ntransparency and confidence in model predictions.\", 'in apple trees. \\n\\uf0b7 Introduced Grad-CAM  interpretability to highlight key image regions influencing classification, bolstering \\ntransparency and confidence in model predictions. \\n\\uf0b7 Implemented a scalable and user-friendly web interface for real-time disease detection , allowing users to upload \\nand analyze images, instantly receive classification results, and visualize model explanations for decision \\ntransparency.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity search and QA chat with OpenAI\n",
        "def openai(openai_api_key, chunks, query):\n",
        "\n",
        "    # Use OpenAI embedding\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "    # Convert text into vectors using FAISS\n",
        "    vectorstores = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "\n",
        "    # Similarity search, retrieve top 3 matches for the query\n",
        "    docs = vectorstores.similarity_search(query=query, k=3)\n",
        "\n",
        "    # ChatOpenAI with 'gpt-3.5-turbo'\n",
        "    llm = ChatOpenAI(model='gpt-3.5-turbo', api_key=openai_api_key)\n",
        "\n",
        "    # QA chain\n",
        "    chain = load_qa_chain(llm=llm, chain_type='stuff')\n",
        "\n",
        "    # Run the chain\n",
        "    response = chain.run(input_documents=docs, question=query)\n",
        "    return response"
      ],
      "metadata": {
        "id": "hgjeseGeYJL8"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Cover Letter"
      ],
      "metadata": {
        "id": "15onaIaYuJ09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cover_letter(resume_text):\n",
        "    query = f'''\n",
        "    Given the resume, give me a nice cover letter.\n",
        "    {resume_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "cover = generate_cover_letter(resume_text=resume_chunks)\n",
        "cover_letter = openai(openai_api_key=openai_api_key, chunks=resume_chunks, query=cover)\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw-99p2dYN8t",
        "outputId": "89716f63-fa0c-4059-b752-906dfe5b3ef3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Hiring Manager,\n",
            "\n",
            "I am writing to express my interest in the position at your company. With a strong background in data science and business analytics, along with a passion for machine learning and natural language processing, I believe I would be a valuable asset to your team.\n",
            "\n",
            "I recently completed my Master of Science in Business Analytics with a Data Science Track at the University of Texas at Dallas. During my studies, I gained hands-on experience with a variety of analytical tools such as SQL, Python, R, Tableau, and Power BI. I also have experience with machine learning libraries such as SkLearn, XGBoost, PyTorch, and FastAI. Additionally, I am proficient in data management tools such as PySpark, Postgres, MongoDB, and AWS Redshift.\n",
            "\n",
            "In my most recent role as a Machine Learning Intern at Smart Data Solutions, I had the opportunity to fine-tune OCR solutions to extract health-related textual data from scanned documents, improving data accuracy. I also leveraged transformer-based models to develop advanced NER systems for accurately identifying and classifying healthcare-associated entities within unstructured medical data. These experiences have enhanced my skills in data preprocessing, model development, and data accuracy improvement.\n",
            "\n",
            "During my time as a Data Intern at SplashBI, I developed an employee attrition prediction model with a high recall rate and accuracy using various machine learning models in Python. I also deployed a dynamic Tableau dashboard to explore attrition trends and provide insights for proactive attrition risk mitigation. Additionally, I gained experience in data extraction and manipulation using SQL queries in AWS Redshift to develop analysis reports and presentations for senior management.\n",
            "\n",
            "In my academic projects, I worked on a Natural Language Processing interface to Postgres, scraping data from websites and developing language models for dynamic querying. I also built a multi-label classification system using deep learning models to accurately classify foliar disease in apple trees. These projects demonstrate my ability to apply my technical skills to real-world problems and deliver impactful solutions.\n",
            "\n",
            "I am confident that my technical skills, analytical mindset, and passion for data science make me a strong candidate for this position. I am eager to contribute my expertise and collaborate with your team to drive data-driven insights and solutions. Thank you for considering my application.\n",
            "\n",
            "Sincerely,\n",
            "Aravind Raj Palepu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Summary"
      ],
      "metadata": {
        "id": "OmcDYZMVuFeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_resume_summary(resume_text):\n",
        "    query = f'''\n",
        "    Given the resume, give me a summary of the resume.\n",
        "    {resume_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "summary = generate_resume_summary(resume_text=resume_chunks)\n",
        "resume_summary = openai(openai_api_key=openai_api_key, chunks=resume_chunks, query=summary)\n",
        "print(f\"Your resume summary: \\n {resume_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shEh9ozZcoXz",
        "outputId": "ba92a1cb-ad7a-422c-cb24-4f4ebb678f24"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aravind Raj Palepu is a professional with a strong background in business analytics and data science. He has a Master of Science degree in Business Analytics with a Data Science Track from the University of Texas at Dallas, and a Bachelor of Business Administration and Bachelor of Laws from Symbiosis International University.\n",
            "\n",
            "Aravind has a range of technical skills, including SkLearn, XGBoost, PyTorch, FastAI, OpenCV2, NLTK, HuggingFace Transformers, Langchain, and Streamlit. He is proficient in analytical tools such as SQL, Python, R, Tableau, Power B.I, Google Analytics, VBA/Macros, and MS Excel. He also has experience in data management tools like PySpark, Postgres, PL/pgSQL, MongoDB, Databricks, Apache Airflow, and AWS Redshift. Aravind holds certifications in AWS Solutions Architect, OCI Foundations, OCI AI Foundations, and Alteryx Micro-Credentials.\n",
            "\n",
            "In terms of professional experience, Aravind worked as a Machine Learning Intern at Smart Data Solutions, where he fine-tuned OCR solutions to extract health-related textual data from scanned documents, improving data accuracy. He also leveraged transformer-based models to develop advanced NER systems for accurately identifying and classifying healthcare-associated entities. Additionally, he deployed a dynamic Tableau dashboard to analyze attrition trends and contributed to a 25% enhancement in the efficacy of retention strategies. Aravind also executed data extraction and manipulation using SQL queries in AWS Redshift.\n",
            "\n",
            "In his academic projects, Aravind developed a natural language processing interface to Postgres, scraped data from Tesla's preowned inventory website, and developed a large language model application using Langchain, Google PaLM 2, Hugging Face Transformers, and Streamlit. He also built a robust multi-label classification system for detecting plant pathology and implemented a user-friendly web interface for real-time disease detection.\n",
            "\n",
            "Overall, Aravind Raj Palepu has a strong academic background and relevant professional experience in machine learning, data analysis, and data management. He possesses a diverse skill set and has showcased his expertise through various projects and internships.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggest Strengths"
      ],
      "metadata": {
        "id": "xhdfSW13t9w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_resume_strengths(resume_text):\n",
        "    query = f'''\n",
        "    Given the resume, give me the strengths of the resume.\n",
        "    {resume_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "strengths = generate_resume_strengths(resume_text=txt)\n",
        "resume_strengths = openai(openai_api_key=openai_api_key, chunks=resume_chunks, query=strengths)\n",
        "print(f\"Your resume strengths: \\n {resume_strengths}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJQXwh-Fc1E5",
        "outputId": "a102a9e7-001f-4773-8e7f-4104aae4a0e0"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your resume strengths: \n",
            " Strengths of the resume include:\n",
            "\n",
            "1. Strong educational background: The candidate holds a Bachelor's degree in Business Administration and Bachelor of Laws from Symbiosis International University and is currently pursuing a Master's degree in Business Analytics with a Data Science track from the University of Texas at Dallas.\n",
            "\n",
            "2. Technical skills: The candidate has a wide range of technical skills, including SkLearn, XGBoost, PyTorch, FastAI, OpenCV2, NLTK, HuggingFace Transformers, Langchain, Streamlit, SQL, Python, R, Tableau, Power B.I, Google Analytics, VBA/Macros, MS Excel, PySpark, Postgres, PL/pgSQL, MongoDB, Databricks, Apache Airflow, and AWS Redshift.\n",
            "\n",
            "3. Professional experience: The candidate has practical experience as a Machine Learning Intern at Smart Data Solutions, where they fine-tuned OCR solutions and leveraged transformer-based models for NER. They also have experience as a Data Intern at SplashBI, where they developed an employee attrition prediction model, deployed a dynamic Tableau dashboard, and executed data extraction and manipulation using SQL queries in AWS Redshift.\n",
            "\n",
            "4. Certifications: The candidate has certifications in AWS Solutions Architect, OCI Foundations, OCI AI Foundations, and Alteryx Micro-Credentials, demonstrating their proficiency in cloud computing and data analytics.\n",
            "\n",
            "5. Academic projects: The candidate has completed relevant academic projects, including a Natural Language Processing Interface to Postgres and a Plant Pathology Detection project. These projects showcase their ability to scrape data, develop machine learning models, implement interpretability techniques, and create user-friendly web interfaces for real-time analysis.\n",
            "\n",
            "Overall, the resume demonstrates a strong combination of education, technical skills, practical experience, and relevant projects, making the candidate a strong candidate for roles in business analytics and data science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggest Weaknesses"
      ],
      "metadata": {
        "id": "kqi1wZ_QtjMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_resume_weaknesses(resume_text):\n",
        "    query = f'''\n",
        "    Given the resume, give me the weaknesses of the resume.\n",
        "    {resume_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "weaknesses = generate_resume_weaknesses(resume_text=resume_chunks)\n",
        "resume_weaknesses = openai(openai_api_key=openai_api_key, chunks=resume_chunks, query=weaknesses)\n",
        "print(f\"Your resume weaknesses: \\n {resume_weaknesses}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBiMUXcPdO-H",
        "outputId": "536accc0-fa7f-4c1a-855d-5022c6ca92f7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your resume weaknesses: \n",
            " Based on the given resume, it is difficult to identify any specific weaknesses. The resume highlights relevant education, technical skills, and professional experience. However, it is important to note that the resume does not mention any specific achievements or projects in the field of Data Science or Business Analytics. Additionally, there is limited information about the duration and scope of the professional experience. It would be beneficial to provide more specific details and accomplishments in these areas to strengthen the resume.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggest Skills"
      ],
      "metadata": {
        "id": "5V4npoWQt53N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_skillSuggest(resume_text):\n",
        "    query = f'''\n",
        "    Given the resume, suggest me some skills/courses I need to work on.\n",
        "    {resume_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "skillSuggest = generate_skillSuggest(resume_text=resume_chunks)\n",
        "skill_suggest = openai(openai_api_key=openai_api_key, chunks=resume_chunks, query=skillSuggest)\n",
        "print(f\"Your skill suggestions: \\n {skill_suggest}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwhbeWZzds2C",
        "outputId": "2da34f9c-b38d-4161-a946-ff1c28d8c876"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your skill suggestions: \n",
            " Based on the provided resume, some skills/courses you may want to consider working on are:\n",
            "\n",
            "1. Deep Learning: Since you already have experience with machine learning models, it would be beneficial to deepen your understanding of deep learning techniques and frameworks such as TensorFlow or Keras.\n",
            "\n",
            "2. Natural Language Processing (NLP): You have worked on a project related to natural language processing, so further developing your skills in this area would be valuable. Consider exploring advanced NLP techniques, such as sentiment analysis, text generation, or language translation.\n",
            "\n",
            "3. Data Management: While you have experience with SQL and databases like Postgres, expanding your knowledge in data management tools and technologies like PySpark, MongoDB, and Apache Airflow would be beneficial in handling large-scale data processing and analysis.\n",
            "\n",
            "4. Cloud Computing: Given your experience with AWS Redshift and the AWS Solutions Architect certification, consider exploring other cloud platforms like Microsoft Azure or Google Cloud. Developing skills in cloud computing can enhance your ability to work with big data and deploy scalable solutions.\n",
            "\n",
            "5. Data Visualization: You have experience with Tableau and Power BI, but consider expanding your knowledge in other data visualization tools such as matplotlib and seaborn in Python. This will allow you to create more customized and interactive visualizations.\n",
            "\n",
            "6. Advanced Statistical Techniques: Building on your analytical skills, consider learning advanced statistical techniques such as time series analysis, clustering, or Bayesian statistics. These techniques can provide deeper insights and help you tackle more complex data problems.\n",
            "\n",
            "7. Communication and Presentation Skills: As indicated in your experience, you have developed reports and presentations for senior management. Improving your communication and presentation skills can make your work more impactful and help you effectively convey insights to stakeholders.\n",
            "\n",
            "Remember to tailor your skill development based on your career goals and areas of interest within the field of data science and analytics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skills Extract"
      ],
      "metadata": {
        "id": "kQfox-zbqtUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf_document:\n",
        "        num_pages = pdf_document.page_count\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_document[page_num]\n",
        "            text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "pdf_path = \"/content/jd.pdf\"\n",
        "pdf_text = extract_text_from_pdf(pdf_path)"
      ],
      "metadata": {
        "id": "R7DAEn6g99rC"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the jd text into chunks\n",
        "jd_text_splitter = RecursiveCharacterTextSplitter(chunk_size=700,\n",
        "                                               chunk_overlap=200,\n",
        "                                               length_function=len)\n",
        "\n",
        "jd_chunks = jd_text_splitter.split_text(text=pdf_text)\n",
        "print(jd_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7WHREBe7ncz",
        "outputId": "a6bd80ed-b7e2-4526-f5f4-740428ba8444"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Company Description\\nHarsco is recognized for technical leadership and worldwide experience in virtually all major\\naspects of railway track maintenance. We enable railroads to operate at peak efficiency over\\nsmooth, precisely aligned track that increases railway safety while reducing fuel consumption\\nand other key operating costs. Our broad array of equipment and services support every type of\\nrailway operator, from major national and international railway systems, to short lines and\\nhigh-speed urban transit networks.\\nJob Description\\nWe are looking for a driven team member to contribute to the development of our technology', 'high-speed urban transit networks.\\nJob Description\\nWe are looking for a driven team member to contribute to the development of our technology\\nproduct serving in area of automating railway track equipment and improving safety of the\\nrailroad operation.\\nThis presents an exceptional opportunity to enhance professional expertise and contribute to a\\nspecialized team. As an AI Machine Learning Engineer, the individual in this role typically works\\nfull-time, focusing on designing and developing scalable solutions using AI tools and machine\\nlearning models. The primary responsibilities include addressing various neural network-related', 'full-time, focusing on designing and developing scalable solutions using AI tools and machine\\nlearning models. The primary responsibilities include addressing various neural network-related\\nchallenges in the railroad and transportation sectors. This involves leveraging big data\\ncomputation and storage tools to create prototypes and datasets, conducting model training and\\nevaluations, integrating solutions, performing bench tests and onsite tests, tuning, and\\nmonitoring. Proficiency in languages such as C and C++ is required, along with software\\ndevelopment for Linux platforms. Successful execution of responsibilities is expected to open up', 'monitoring. Proficiency in languages such as C and C++ is required, along with software\\ndevelopment for Linux platforms. Successful execution of responsibilities is expected to open up\\nsignificant career opportunities within Harsco Rail.\\nTeam get to work on popular products that serve major railroads across the globe. Engineers\\nhere are designing products that make a meaningful impact in the railroad industry. We use\\ncutting edge technology to design & develop next generation railroad equipment & digital\\ndevices. Watch some of our manned/unmanned track equipment & technology products in\\naction at www.harscorail.com & https://www.protrantechnology.com/\\nYour responsibilities', 'devices. Watch some of our manned/unmanned track equipment & technology products in\\naction at www.harscorail.com & https://www.protrantechnology.com/\\nYour responsibilities\\nDesign and develop real time AI – Neural Network solutions for railway maintenance\\nequipment. Implementing appropriate ML algorithms.\\nWrite clean, documented code following best practices.\\nDevelop and implement communication protocols.\\nWork independently and collaboratively with a motivated team.\\nGenerate requirements and design documentation.\\nPlan for, design, and deliver testing, and tested products into the QA process.\\nApply communication and problem-solving skills to solve software issues related to the design,', 'Plan for, design, and deliver testing, and tested products into the QA process.\\nApply communication and problem-solving skills to solve software issues related to the design,\\ndevelopment, deployment, testing, and operation of systems.\\nMeet deadlines to ensure projects are completed within acceptable time and cost targets.\\nWillingness and ability to travel up to 15% of time.\\nOther duties may apply as required.\\nQualifications\\nEducation\\nMaster’s / Bachelor’s degree in Software Engineering or similar experience.\\nExperience\\n3+ years of experience in developing CNN, R-CNN type neural network for computer vision\\ntasks.\\n3+ years of experience in Software development using C++/Python language.', 'Experience\\n3+ years of experience in developing CNN, R-CNN type neural network for computer vision\\ntasks.\\n3+ years of experience in Software development using C++/Python language.\\nExperience with Supervised and Semi-Supervised Learning, Deep Learning, Support Vector\\nMachines, Linear and Logistic Regression.\\nWorking knowledge of AI Framework such as TensorFlow, Café, PyTorch, Keras, Darknet and\\nOpenCV.\\nWorking knowledge of AI edge devices such as NVIDIA Jetson / Nano / Orin.\\nKnowledge of the Linux Operating System.\\nWhat Makes You Stand Out – Preferred Experience & Skill\\nExperience using statistical computer languages (R, Python, SQL etc.) to manipulate data and', 'Knowledge of the Linux Operating System.\\nWhat Makes You Stand Out – Preferred Experience & Skill\\nExperience using statistical computer languages (R, Python, SQL etc.) to manipulate data and\\ndraw insights from large data sets.\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques (semantic segmentation, clustering,\\ndecision tree learning, artificial neural networks, etc.) and their real-world\\nadvantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of\\ndistributions, statistical tests, and proper usage, etc.) and experience with applications.', 'advantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of\\ndistributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience with edge computing & controlling devices (On-device deployment in C/C++ or\\nsimilar) for real time application.\\nExperience with optimizing neural networks to perform well on low-power mobile platforms (e.g.\\npruning, distillation, quantization).\\nEssential Functions\\nAble to follow directions, detail-oriented, patient, and quality focused.\\nThe ability to attend work predictably and regularly.\\nThe ability to deal politely and professionally with team members and colleagues.', \"The ability to attend work predictably and regularly.\\nThe ability to deal politely and professionally with team members and colleagues.\\nThe ability to manage several tasks at once.\\nThe ability to use a computer to communicate, create, and access information.\\nAvailable to work overtime as needed.\\nWhat you’ll Get\\nAt Harsco Rail, You Are Empowered To Create a Career That Will Take You To Where You Want\\nTo Go While Working In An Inclusive Team Environment. Here, You'll Enjoy The Freedom To\\nExplore New Projects, The Support To Think Outside The Box And The Advanced Tools And\\nTechnology That Foster Innovation And Achievement. Additionally, We Offer a Comprehensive\", 'Explore New Projects, The Support To Think Outside The Box And The Advanced Tools And\\nTechnology That Foster Innovation And Achievement. Additionally, We Offer a Comprehensive\\nReward Package To Help You Get Started On Your New Career Path, Including\\nFlexible work arrangements (Hybrid work schedule)\\nHighly competitive base pay and performance bonuses\\nPaid time off\\nSign in bonus & Relocations assistance\\nSavings & Retirement benefits (401K)\\nHealthcare benefits – Health insurance, Contribution to HSA & Various Wellness program\\n(Onsite Clinic)\\nEmployee Assistance Programs\\nTuition assistance\\nFitness subsidies and on-site gyms at Columbia location', '(Onsite Clinic)\\nEmployee Assistance Programs\\nTuition assistance\\nFitness subsidies and on-site gyms at Columbia location\\nVisa Sponsorship is available for this position (Individual who are in US with legal work permit)\\nAdditional Information\\nWe provide equal employment opportunities (EEO) to all employees and applicants for\\nemployment without regard to race, color, religion, sex, national origin, age, disability, veteran\\nstatus or genetics. This policy applies to all terms and conditions of employment, including\\nrecruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence,\\ncompensation and training.', 'recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence,\\ncompensation and training.\\nIf you have a difficulty applying for any job posted on Harsco Rail’s website because a disability\\nprevents you from using the online system, Harsco Rail offers the following alternate application\\nprocedure: Contact Shannon Godby at 803-822-7589 and Harsco Rail will arrange for an\\nalternate method of applying and will consider your application together with all other\\napplications received for the job. Please call only for disability application.All your information\\nwill be kept confidential according to EEO guidelines.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity search and QA chat with OpenAI\n",
        "def jd_openai(openai_api_key, chunks, query):\n",
        "\n",
        "    # Use OpenAI embedding\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "    # Convert text into vectors using FAISS\n",
        "    vectors = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "\n",
        "    # Similarity search, retrieve top 3 matches for the query\n",
        "    docx = vectors.similarity_search(query=query, k=3)\n",
        "\n",
        "    # ChatOpenAI with 'gpt-3.5-turbo'\n",
        "    llm = ChatOpenAI(model='gpt-3.5-turbo', api_key=openai_api_key)\n",
        "\n",
        "    # QA chain\n",
        "    chain = load_qa_chain(llm=llm, chain_type='stuff')\n",
        "\n",
        "    # Run the chain\n",
        "    response = chain.run(input_documents=docx, question=query)\n",
        "    return response"
      ],
      "metadata": {
        "id": "zqrBZAWqZfgR"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_keywords_jd(jd_text):\n",
        "    query = f'''\n",
        "    Given the job description, give me a list of all keywords. Segment into technical, professional and soft skills.\n",
        "    {jd_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "jd_res = recognize_keywords_jd(jd_text=pdf_text)\n",
        "jd_keywords = openai(openai_api_key=openai_api_key, chunks=jd_chunks, query=jd_res)\n",
        "print(f\"Skill required for the job: \\n {jd_keywords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQL2ewyEbFwR",
        "outputId": "c3bd2a92-d86e-4895-d607-3f62c93b8a95"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skill required for the job: \n",
            " Technical Skills:\n",
            "- C\n",
            "- C++\n",
            "- Linux platforms\n",
            "- AI tools\n",
            "- Machine learning models\n",
            "- Neural networks\n",
            "- Big data computation and storage tools\n",
            "- Prototypes and datasets\n",
            "- Model training and evaluations\n",
            "- Integration of solutions\n",
            "- Bench tests and onsite tests\n",
            "- Tuning and monitoring\n",
            "- CNN (Convolutional Neural Network)\n",
            "- R-CNN type neural network\n",
            "- Computer vision tasks\n",
            "- Supervised and Semi-Supervised Learning\n",
            "- Deep Learning\n",
            "- Support Vector Machines\n",
            "- Linear and Logistic Regression\n",
            "- AI Frameworks (TensorFlow, Café, PyTorch, Keras, Darknet, OpenCV)\n",
            "- AI edge devices (NVIDIA Jetson / Nano / Orin)\n",
            "- Linux Operating System\n",
            "- Statistical computer languages (R, Python, SQL)\n",
            "- Data manipulation and analysis\n",
            "- Data architectures\n",
            "- Machine learning techniques (semantic segmentation, clustering, decision tree learning, artificial neural networks)\n",
            "- Statistical techniques and concepts\n",
            "- Edge computing\n",
            "- Optimizing neural networks for low-power mobile platforms\n",
            "\n",
            "Professional Skills:\n",
            "- Software development\n",
            "- Clean code writing and documentation\n",
            "- Communication protocols implementation\n",
            "- Independent and collaborative work\n",
            "- Requirements and design documentation generation\n",
            "- Testing and QA process\n",
            "- Problem-solving skills\n",
            "- Meeting deadlines\n",
            "- Travel willingness and ability\n",
            "\n",
            "Soft Skills:\n",
            "- Driven and motivated\n",
            "- Attention to detail\n",
            "- Patience\n",
            "- Quality-focused\n",
            "- Professionalism\n",
            "- Task management\n",
            "- Computer proficiency\n",
            "- Ability to work predictably and regularly\n",
            "- Ability to work with a team\n",
            "- Ability to manage multiple tasks\n",
            "- Strong communication skills\n",
            "\n",
            "Note: This is not an exhaustive list, and there may be additional skills and qualifications that are not mentioned in the given context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_keywords(resume_text):\n",
        "    query = f'''\n",
        "    Given the resume, give me a list of all my technical, professional and soft skills.\n",
        "    {resume_text}\n",
        "              '''\n",
        "    return query\n",
        "\n",
        "resume_res = resume_keywords(resume_text=txt)\n",
        "resume_keywords = openai(openai_api_key=openai_api_key, chunks=resume_chunks, query=resume_res)\n",
        "print(f\"Skills you possess: \\n {resume_keywords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aMk-UYejszv",
        "outputId": "f0fe5ece-b6cf-4207-c1bc-f85e2deef7c1"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your skill suggestions: \n",
            " Technical Skills:\n",
            "- SkLearn\n",
            "- XGBoost\n",
            "- PyTorch\n",
            "- FastAI\n",
            "- OpenCV2\n",
            "- NLTK\n",
            "- HuggingFace Transformers\n",
            "- Langchain\n",
            "- Streamlit\n",
            "- SQL\n",
            "- Python\n",
            "- R\n",
            "- Tableau\n",
            "- Power BI\n",
            "- Google Analytics\n",
            "- VBA/Macros\n",
            "- MS Excel\n",
            "- PySpark\n",
            "- Postgres\n",
            "- PL/pgSQL\n",
            "- MongoDB\n",
            "- Databricks\n",
            "- Apache Airflow\n",
            "- AWS Redshift\n",
            "\n",
            "Professional Skills:\n",
            "- Machine Learning\n",
            "- OCR\n",
            "- NER (Named Entity Recognition)\n",
            "- Data Extraction\n",
            "- Data Manipulation\n",
            "- Data Analysis\n",
            "- Employee Attrition Prediction\n",
            "- Tableau Dashboard Development\n",
            "- SQL Queries\n",
            "- AWS Redshift\n",
            "- Presentation Skills\n",
            "\n",
            "Soft Skills:\n",
            "- Communication\n",
            "- Problem-Solving\n",
            "- Teamwork\n",
            "- Time Management\n",
            "- Attention to Detail\n",
            "- Analytical Thinking\n",
            "- Presentation Skills\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Analyzer"
      ],
      "metadata": {
        "id": "88tRy4IdlZNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_text = \"Resume: \\n\"\n",
        "combined_text += txt\n",
        "combined_text += \"\\n \\n ------------- end of resume ------------- \\n \\nJob Description: \\n \"\n",
        "combined_text += pdf_text\n",
        "combined_text += \"\\n \\n ------------- end of job description ------------- \\n\""
      ],
      "metadata": {
        "id": "DHWVD-wLqZGO"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the resume text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700,\n",
        "                                               chunk_overlap=0,\n",
        "                                               length_function=len)\n",
        "\n",
        "combined_text_chunks = text_splitter.split_text(text=combined_text)\n",
        "print(combined_text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj_mfiLAvvE6",
        "outputId": "3ab4933b-17a2-4b47-aef6-12acf1a43956"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Resume: \\nARAVIND RAJ PALEPU   \\nRichardson, TX – 75082, (314)-386-7056 | aravindrajpalepu@gmail.com  | LinkedIn | GitHub | Tableau Public   \\n \\nEDUCATION   \\nUniversity of Texas at Dallas                    May 2024  \\nMaster of Science, Business Analytics - Data Science Track         \\nSymbiosis International University                               May 2021  \\nBachelor of Business Administration and Bachelor of Laws \\n                               \\nTECHNICAL SKILLS   \\nTechnical: SkLearn, XGBoost, PyTorch, FastAI, OpenCV2, NLTK, HuggingFace Transformers, Langchain, Streamlit \\nAnalytical Tools: SQL, Python, R, Tableau, Power B.I , Google Analytics, VBA/Macros, MS Excel', 'Data Management:  PySpark, Postgres, PL/pgSQL, MongoDB, Databricks, Apache Airflow, AWS Redshift \\nCertifications:  AWS Solutions Architect, OCI Foundations, OCI AI Foundations, Alteryx Micro-Credentials \\n \\nPROFESSIONAL EXPERIENCE   \\nSmart Data Solutions, Eagan, Minnesota                January 2024 – May 2024 \\nMachine Learning Intern \\n\\uf0b7 Fined-tuned OCR solutions to efficiently extract health related textual data from scanned documents, thereby \\nenhancing data accuracy.  \\n\\uf0b7 Leveraged transformer-based models to deliver advanced NER systems to accurately identify and classify targeted', 'healthcare associated entities, including PII, diseases, medications, and medical procedures within a wide range of \\nunstructured medical data.  \\nSplashBI, Hyderabad, India                              January 2022 – July 2022 \\nData Intern  \\n\\uf0b7 Developed an employee attrition prediction model  with 93% recall  and 91% accuracy  using various machine \\nlearning models in Python, providing valuable insights into factors influencing employee turnover.  \\n\\uf0b7 Deployed a dynamic Tableau dashboard, facilitating a nuanced exploration of attrition trends, thereby enabling \\nproactive attrition risk mitigation , and contributing to a 25% enhancement in the efficacy of retention strategies.', \"\\uf0b7 Executed data extraction and manipulation using SQL queries in AWS Redshift  to develop analysis reports and \\npresentations for the senior management.  \\n \\nACADEMIC PROJECTS   \\nNatural Language processing Interface to Postgres       August 2023 – December 2023  \\n\\uf0b7 Scraped data from Tesla's preowned inventory website using Selenium , capturing key variables related to car \\nlistings and established comprehensive data quality checks to validate data types and identify anomalies in data.  \\n\\uf0b7 Developed a large language model application using Langchain , Google PaLM 2 , Hugging Face Transformers  \\nand Streamlit  to dynamically query the data in Postgres in natural language.\", \"\\uf0b7 Generated word embeddings using Chroma's sentence transformers for enhanced semantic search, elevating the \\nprecision and effectiveness of information retrieval.  \\nPlant Pathology Detection         August 2023 – December 2023 \\n\\uf0b7 Built a robust multi-label classification system using ResNet and GoogLeNet  to accurately classify Foliar disease  \\nin apple trees. \\n\\uf0b7 Introduced Grad-CAM  interpretability to highlight key image regions influencing classification, bolstering \\ntransparency and confidence in model predictions. \\n\\uf0b7 Implemented a scalable and user-friendly web interface for real-time disease detection , allowing users to upload\", 'and analyze images, instantly receive classification results, and visualize model explanations for decision \\ntransparency. \\n \\n ------------- end of resume ------------- \\n \\nJob Description: \\n Company Description\\nHarsco is recognized for technical leadership and worldwide experience in virtually all major\\naspects of railway track maintenance. We enable railroads to operate at peak efficiency over\\nsmooth, precisely aligned track that increases railway safety while reducing fuel consumption\\nand other key operating costs. Our broad array of equipment and services support every type of\\nrailway operator, from major national and international railway systems, to short lines and', 'high-speed urban transit networks.\\nJob Description\\nWe are looking for a driven team member to contribute to the development of our technology\\nproduct serving in area of automating railway track equipment and improving safety of the\\nrailroad operation.\\nThis presents an exceptional opportunity to enhance professional expertise and contribute to a\\nspecialized team. As an AI Machine Learning Engineer, the individual in this role typically works\\nfull-time, focusing on designing and developing scalable solutions using AI tools and machine\\nlearning models. The primary responsibilities include addressing various neural network-related', 'challenges in the railroad and transportation sectors. This involves leveraging big data\\ncomputation and storage tools to create prototypes and datasets, conducting model training and\\nevaluations, integrating solutions, performing bench tests and onsite tests, tuning, and\\nmonitoring. Proficiency in languages such as C and C++ is required, along with software\\ndevelopment for Linux platforms. Successful execution of responsibilities is expected to open up\\nsignificant career opportunities within Harsco Rail.\\nTeam get to work on popular products that serve major railroads across the globe. Engineers\\nhere are designing products that make a meaningful impact in the railroad industry. We use', 'cutting edge technology to design & develop next generation railroad equipment & digital\\ndevices. Watch some of our manned/unmanned track equipment & technology products in\\naction at www.harscorail.com & https://www.protrantechnology.com/\\nYour responsibilities\\nDesign and develop real time AI – Neural Network solutions for railway maintenance\\nequipment. Implementing appropriate ML algorithms.\\nWrite clean, documented code following best practices.\\nDevelop and implement communication protocols.\\nWork independently and collaboratively with a motivated team.\\nGenerate requirements and design documentation.\\nPlan for, design, and deliver testing, and tested products into the QA process.', 'Apply communication and problem-solving skills to solve software issues related to the design,\\ndevelopment, deployment, testing, and operation of systems.\\nMeet deadlines to ensure projects are completed within acceptable time and cost targets.\\nWillingness and ability to travel up to 15% of time.\\nOther duties may apply as required.\\nQualifications\\nEducation\\nMaster’s / Bachelor’s degree in Software Engineering or similar experience.\\nExperience\\n3+ years of experience in developing CNN, R-CNN type neural network for computer vision\\ntasks.\\n3+ years of experience in Software development using C++/Python language.', 'Experience with Supervised and Semi-Supervised Learning, Deep Learning, Support Vector\\nMachines, Linear and Logistic Regression.\\nWorking knowledge of AI Framework such as TensorFlow, Café, PyTorch, Keras, Darknet and\\nOpenCV.\\nWorking knowledge of AI edge devices such as NVIDIA Jetson / Nano / Orin.\\nKnowledge of the Linux Operating System.\\nWhat Makes You Stand Out – Preferred Experience & Skill\\nExperience using statistical computer languages (R, Python, SQL etc.) to manipulate data and\\ndraw insights from large data sets.\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques (semantic segmentation, clustering,', 'decision tree learning, artificial neural networks, etc.) and their real-world\\nadvantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of\\ndistributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience with edge computing & controlling devices (On-device deployment in C/C++ or\\nsimilar) for real time application.\\nExperience with optimizing neural networks to perform well on low-power mobile platforms (e.g.\\npruning, distillation, quantization).\\nEssential Functions\\nAble to follow directions, detail-oriented, patient, and quality focused.\\nThe ability to attend work predictably and regularly.', \"The ability to deal politely and professionally with team members and colleagues.\\nThe ability to manage several tasks at once.\\nThe ability to use a computer to communicate, create, and access information.\\nAvailable to work overtime as needed.\\nWhat you’ll Get\\nAt Harsco Rail, You Are Empowered To Create a Career That Will Take You To Where You Want\\nTo Go While Working In An Inclusive Team Environment. Here, You'll Enjoy The Freedom To\\nExplore New Projects, The Support To Think Outside The Box And The Advanced Tools And\\nTechnology That Foster Innovation And Achievement. Additionally, We Offer a Comprehensive\\nReward Package To Help You Get Started On Your New Career Path, Including\", 'Flexible work arrangements (Hybrid work schedule)\\nHighly competitive base pay and performance bonuses\\nPaid time off\\nSign in bonus & Relocations assistance\\nSavings & Retirement benefits (401K)\\nHealthcare benefits – Health insurance, Contribution to HSA & Various Wellness program\\n(Onsite Clinic)\\nEmployee Assistance Programs\\nTuition assistance\\nFitness subsidies and on-site gyms at Columbia location\\nVisa Sponsorship is available for this position (Individual who are in US with legal work permit)\\nAdditional Information\\nWe provide equal employment opportunities (EEO) to all employees and applicants for', 'employment without regard to race, color, religion, sex, national origin, age, disability, veteran\\nstatus or genetics. This policy applies to all terms and conditions of employment, including\\nrecruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence,\\ncompensation and training.\\nIf you have a difficulty applying for any job posted on Harsco Rail’s website because a disability\\nprevents you from using the online system, Harsco Rail offers the following alternate application\\nprocedure: Contact Shannon Godby at 803-822-7589 and Harsco Rail will arrange for an\\nalternate method of applying and will consider your application together with all other', 'applications received for the job. Please call only for disability application.All your information\\nwill be kept confidential according to EEO guidelines.', '------------- end of job description -------------']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity search and QA chat with OpenAI\n",
        "def resume_scorer(openai_api_key, chunks, query):\n",
        "\n",
        "    # Use OpenAI embedding\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "    # Convert text into vectors using FAISS\n",
        "    vectors = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "\n",
        "    # Similarity search, retrieve top 3 matches for the query\n",
        "    docx = vectors.similarity_search(query=query)\n",
        "\n",
        "    # ChatOpenAI with 'gpt-3.5-turbo'\n",
        "    llm = ChatOpenAI(model='gpt-3.5-turbo', api_key=openai_api_key)\n",
        "\n",
        "    # QA chain\n",
        "    chain = load_qa_chain(llm=llm, chain_type='stuff')\n",
        "\n",
        "    # Run the chain\n",
        "    response = chain.run(input_documents=docx, question=query)\n",
        "    return response"
      ],
      "metadata": {
        "id": "Ea24BU4iweJE"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_analyzer(combined_text):\n",
        "    query = f\"\"\"\n",
        "    Evaluate the resume based on the job description in the text below. Give me a score between 0 and 100. Both the\n",
        "    {combined_text}\n",
        "              \"\"\"\n",
        "    return query\n",
        "\n",
        "query = resume_analyzer(combined_text=combined_text)\n",
        "score_and_analysis = resume_scorer(openai_api_key=openai_api_key, chunks=combined_text_chunks, query=query)\n",
        "print(f\"Score: \\n {score_and_analysis}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b1_F3lksn8v",
        "outputId": "7dd53aef-f7db-48c1-f937-de2413ce6465"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: \n",
            " Based on the job description provided, here's an evaluation of the resume:\n",
            "\n",
            "1. Education: The candidate has a Master of Science degree in Business Analytics with a Data Science Track, which aligns with the job requirements. Additionally, the candidate has a Bachelor's degree in Business Administration and Bachelor of Laws, which may not be directly related to the job but still demonstrates a strong educational background. Score: 85\n",
            "\n",
            "2. Technical Skills: The candidate has a strong technical skillset, including experience with SkLearn, XGBoost, PyTorch, FastAI, OpenCV2, NLTK, HuggingFace Transformers, Langchain, and Streamlit. They also have experience with SQL, Python, R, Tableau, Power B.I, Google Analytics, VBA/Macros, and MS Excel, which are relevant analytical tools. Additionally, they have experience with data management tools like PySpark, Postgres, PL/pgSQL, MongoDB, Databricks, Apache Airflow, and AWS Redshift. Score: 90\n",
            "\n",
            "3. Professional Experience: The candidate has relevant experience as a Machine Learning Intern at Smart Data Solutions, where they worked on OCR solutions and NER systems. They also have experience as a Data Intern at SplashBI, where they developed an employee attrition prediction model and deployed a dynamic Tableau dashboard. These experiences demonstrate their skills in machine learning and data analysis. Score: 80\n",
            "\n",
            "4. Academic Projects: The candidate has worked on projects related to natural language processing and image classification, which align with the job requirements. They have used technologies like Selenium, Google PaLM 2, Hugging Face Transformers, and Streamlit. These projects showcase their ability to work on real-world data problems and develop AI solutions. Score: 90\n",
            "\n",
            "Overall, the resume aligns well with the job description and showcases relevant skills and experiences. I would give it a score of 85 out of 100.\n"
          ]
        }
      ]
    }
  ]
}